{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('priority_1k_labelled.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>category-sentiment</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kotor berdebu. Saya tdk berhenti bersin ketika...</td>\n",
       "      <td>kebersihan-neg</td>\n",
       "      <td>kebersihan</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kotor berdebu. Saya tdk berhenti bersin ketika...</td>\n",
       "      <td>wifi_p1-neg</td>\n",
       "      <td>wifi_p1</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kamar ada semutnya. kamar mandi bermasalah. bu...</td>\n",
       "      <td>kebersihan-neg</td>\n",
       "      <td>kebersihan</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kamar mandi bau, airnya bau</td>\n",
       "      <td>bau_P1-neg</td>\n",
       "      <td>bau_P1</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tak sesuai espektasi, kamar sempit, pintu kama...</td>\n",
       "      <td>service-neg</td>\n",
       "      <td>service</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review category-sentiment  \\\n",
       "0  Kotor berdebu. Saya tdk berhenti bersin ketika...     kebersihan-neg   \n",
       "1  Kotor berdebu. Saya tdk berhenti bersin ketika...        wifi_p1-neg   \n",
       "2  kamar ada semutnya. kamar mandi bermasalah. bu...     kebersihan-neg   \n",
       "3                        Kamar mandi bau, airnya bau         bau_P1-neg   \n",
       "4  tak sesuai espektasi, kamar sempit, pintu kama...        service-neg   \n",
       "\n",
       "     category sentiment  Unnamed: 4  \n",
       "0  kebersihan       neg         NaN  \n",
       "1     wifi_p1       neg         NaN  \n",
       "2  kebersihan       neg         NaN  \n",
       "3      bau_P1       neg         NaN  \n",
       "4     service       neg         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns='category-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review        False\n",
       "category      False\n",
       "sentiment     False\n",
       "Unnamed: 4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_label(x_train, y_train):\n",
    "    y_train_set = []\n",
    "    sent = x_train[0]\n",
    "    X_train_set = [sent]\n",
    "    labels = []\n",
    "    for i in range (len(x_train)):\n",
    "        if sent != x_train[i]:\n",
    "            if (len(labels)>0):\n",
    "                y_train_set.append(labels)\n",
    "            sent = x_train[i]\n",
    "            X_train_set.append(sent)\n",
    "            labels = []\n",
    "        labels.append(y_train[i])\n",
    "    return X_train_set, y_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_all_label(data['review'], data['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = list(zip(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kotor berdebu. Saya tdk berhenti bersin ketika...</td>\n",
       "      <td>[kebersihan, wifi_p1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kamar ada semutnya. kamar mandi bermasalah. bu...</td>\n",
       "      <td>[kebersihan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kamar mandi bau, airnya bau</td>\n",
       "      <td>[bau_P1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tak sesuai espektasi, kamar sempit, pintu kama...</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buruk. kasur ada bekas sperma seprai jg air ba...</td>\n",
       "      <td>[linen_P1, wifi_p1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review                 labels\n",
       "0  Kotor berdebu. Saya tdk berhenti bersin ketika...  [kebersihan, wifi_p1]\n",
       "1  kamar ada semutnya. kamar mandi bermasalah. bu...           [kebersihan]\n",
       "2                        Kamar mandi bau, airnya bau               [bau_P1]\n",
       "3  tak sesuai espektasi, kamar sempit, pintu kama...              [service]\n",
       "4  buruk. kasur ada bekas sperma seprai jg air ba...    [linen_P1, wifi_p1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(data_train, columns=['review', 'labels'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ac_P1', 'air_panas_P1', 'bau_P1', 'general', 'kebersihan',\n",
       "       'linen_P1', 'service', 'sunrise_meal_P1', 'tv_P1', 'wifi_P1',\n",
       "       'wifi_p1'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = df_train.labels\n",
    "y = mlb.fit_transform(y)\n",
    "mlb.classes_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_list = y.tolist()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame(y, columns=mlb.classes_)\n",
    "df_train = df_train.join(df_y)\n",
    "df_train = df_train.drop(columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac_P1</th>\n",
       "      <th>air_panas_P1</th>\n",
       "      <th>bau_P1</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen_P1</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal_P1</th>\n",
       "      <th>tv_P1</th>\n",
       "      <th>wifi_P1</th>\n",
       "      <th>wifi_p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kotor berdebu. Saya tdk berhenti bersin ketika...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kamar ada semutnya. kamar mandi bermasalah. bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kamar mandi bau, airnya bau</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tak sesuai espektasi, kamar sempit, pintu kama...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buruk. kasur ada bekas sperma seprai jg air ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  ac_P1  air_panas_P1  \\\n",
       "0  Kotor berdebu. Saya tdk berhenti bersin ketika...      0             0   \n",
       "1  kamar ada semutnya. kamar mandi bermasalah. bu...      0             0   \n",
       "2                        Kamar mandi bau, airnya bau      0             0   \n",
       "3  tak sesuai espektasi, kamar sempit, pintu kama...      0             0   \n",
       "4  buruk. kasur ada bekas sperma seprai jg air ba...      0             0   \n",
       "\n",
       "   bau_P1  general  kebersihan  linen_P1  service  sunrise_meal_P1  tv_P1  \\\n",
       "0       0        0           1         0        0                0      0   \n",
       "1       0        0           1         0        0                0      0   \n",
       "2       1        0           0         0        0                0      0   \n",
       "3       0        0           0         0        1                0      0   \n",
       "4       0        0           0         1        0                0      0   \n",
       "\n",
       "   wifi_P1  wifi_p1  \n",
       "0        0        1  \n",
       "1        0        0  \n",
       "2        0        0  \n",
       "3        0        0  \n",
       "4        0        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('priority_1k_labelled_onehot.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def tokenize(msg):\n",
    "    clean = [char for char in msg if char not in string.punctuation]\n",
    "    clean = ''.join(clean)\n",
    "    return clean.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "longest = 0\n",
    "for review in df_train.review:\n",
    "    if len(tokenize(review)) > longest:\n",
    "        longest = len(review)\n",
    "print(longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Annisa Nurul Azhar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(df_train.review)\n",
    "sequences = tokenizer.texts_to_sequences(df_train.review)\n",
    "x = pad_sequences(sequences, maxlen=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 703 samples, validate on 79 samples\n",
      "Epoch 1/50\n",
      "703/703 [==============================] - 0s 686us/step - loss: 0.5428 - categorical_accuracy: 0.1408 - val_loss: 0.4326 - val_categorical_accuracy: 0.3165\n",
      "Epoch 2/50\n",
      "703/703 [==============================] - 0s 288us/step - loss: 0.4169 - categorical_accuracy: 0.2276 - val_loss: 0.4210 - val_categorical_accuracy: 0.3418\n",
      "Epoch 3/50\n",
      "703/703 [==============================] - 0s 278us/step - loss: 0.3814 - categorical_accuracy: 0.3670 - val_loss: 0.3835 - val_categorical_accuracy: 0.4304\n",
      "Epoch 4/50\n",
      "703/703 [==============================] - 0s 312us/step - loss: 0.3415 - categorical_accuracy: 0.4296 - val_loss: 0.3541 - val_categorical_accuracy: 0.5443\n",
      "Epoch 5/50\n",
      "703/703 [==============================] - 0s 302us/step - loss: 0.3115 - categorical_accuracy: 0.4893 - val_loss: 0.3295 - val_categorical_accuracy: 0.5443\n",
      "Epoch 6/50\n",
      "703/703 [==============================] - 0s 333us/step - loss: 0.2860 - categorical_accuracy: 0.5292 - val_loss: 0.3163 - val_categorical_accuracy: 0.5570\n",
      "Epoch 7/50\n",
      "703/703 [==============================] - 0s 352us/step - loss: 0.2705 - categorical_accuracy: 0.5320 - val_loss: 0.3070 - val_categorical_accuracy: 0.5443\n",
      "Epoch 8/50\n",
      "703/703 [==============================] - 0s 336us/step - loss: 0.2503 - categorical_accuracy: 0.5704 - val_loss: 0.2900 - val_categorical_accuracy: 0.5949\n",
      "Epoch 9/50\n",
      "703/703 [==============================] - 0s 409us/step - loss: 0.2379 - categorical_accuracy: 0.5519 - val_loss: 0.2777 - val_categorical_accuracy: 0.6076\n",
      "Epoch 10/50\n",
      "703/703 [==============================] - 0s 309us/step - loss: 0.2188 - categorical_accuracy: 0.6003 - val_loss: 0.2637 - val_categorical_accuracy: 0.6076\n",
      "Epoch 11/50\n",
      "703/703 [==============================] - 0s 298us/step - loss: 0.2067 - categorical_accuracy: 0.6273 - val_loss: 0.2574 - val_categorical_accuracy: 0.6329\n",
      "Epoch 12/50\n",
      "703/703 [==============================] - 0s 288us/step - loss: 0.1899 - categorical_accuracy: 0.6230 - val_loss: 0.2485 - val_categorical_accuracy: 0.6076\n",
      "Epoch 13/50\n",
      "703/703 [==============================] - 0s 309us/step - loss: 0.1788 - categorical_accuracy: 0.6415 - val_loss: 0.2480 - val_categorical_accuracy: 0.5949\n",
      "Epoch 14/50\n",
      "703/703 [==============================] - 0s 358us/step - loss: 0.1759 - categorical_accuracy: 0.6373 - val_loss: 0.2430 - val_categorical_accuracy: 0.6076\n",
      "Epoch 15/50\n",
      "703/703 [==============================] - 0s 325us/step - loss: 0.1730 - categorical_accuracy: 0.6245 - val_loss: 0.2366 - val_categorical_accuracy: 0.6203\n",
      "Epoch 16/50\n",
      "703/703 [==============================] - 0s 322us/step - loss: 0.1613 - categorical_accuracy: 0.6415 - val_loss: 0.2417 - val_categorical_accuracy: 0.6076\n",
      "Epoch 17/50\n",
      "703/703 [==============================] - 0s 318us/step - loss: 0.1597 - categorical_accuracy: 0.6415 - val_loss: 0.2379 - val_categorical_accuracy: 0.6329\n",
      "Epoch 18/50\n",
      "703/703 [==============================] - 0s 318us/step - loss: 0.1551 - categorical_accuracy: 0.6344 - val_loss: 0.2417 - val_categorical_accuracy: 0.6076\n",
      "Epoch 19/50\n",
      "703/703 [==============================] - 0s 350us/step - loss: 0.1640 - categorical_accuracy: 0.6373 - val_loss: 0.2405 - val_categorical_accuracy: 0.6076\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 20, input_length=180))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(0.015), loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-simple.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 331us/step\n",
      "loss: 0.251509889047973\n",
      "categorical_accuracy: 0.5663265306122449\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "simple_model = keras.models.load_model('model-simple.h5')\n",
    "metrics = simple_model.evaluate(x_test, y_test)\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 180, 20)           100000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 180, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 178, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 11)                3311      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 121,611\n",
      "Trainable params: 121,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 703 samples, validate on 79 samples\n",
      "Epoch 1/20\n",
      "703/703 [==============================] - 13s 18ms/step - loss: 0.6311 - categorical_accuracy: 0.0882 - val_loss: 0.5594 - val_categorical_accuracy: 0.0886\n",
      "Epoch 2/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.4673 - categorical_accuracy: 0.2020 - val_loss: 0.4321 - val_categorical_accuracy: 0.3165\n",
      "Epoch 3/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.4251 - categorical_accuracy: 0.2262 - val_loss: 0.4313 - val_categorical_accuracy: 0.3165\n",
      "Epoch 4/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.4177 - categorical_accuracy: 0.2262 - val_loss: 0.4266 - val_categorical_accuracy: 0.3165\n",
      "Epoch 5/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.4116 - categorical_accuracy: 0.2262 - val_loss: 0.4199 - val_categorical_accuracy: 0.3165\n",
      "Epoch 6/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.3988 - categorical_accuracy: 0.3115 - val_loss: 0.4051 - val_categorical_accuracy: 0.4304\n",
      "Epoch 7/20\n",
      "703/703 [==============================] - 12s 16ms/step - loss: 0.3731 - categorical_accuracy: 0.4196 - val_loss: 0.3772 - val_categorical_accuracy: 0.4937\n",
      "Epoch 8/20\n",
      "703/703 [==============================] - 12s 16ms/step - loss: 0.3387 - categorical_accuracy: 0.4950 - val_loss: 0.3436 - val_categorical_accuracy: 0.6456\n",
      "Epoch 9/20\n",
      "703/703 [==============================] - 12s 16ms/step - loss: 0.2999 - categorical_accuracy: 0.6145 - val_loss: 0.3074 - val_categorical_accuracy: 0.6456\n",
      "Epoch 10/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.2621 - categorical_accuracy: 0.6771 - val_loss: 0.2793 - val_categorical_accuracy: 0.6835\n",
      "Epoch 11/20\n",
      "703/703 [==============================] - 12s 16ms/step - loss: 0.2319 - categorical_accuracy: 0.6942 - val_loss: 0.2620 - val_categorical_accuracy: 0.6962\n",
      "Epoch 12/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.2107 - categorical_accuracy: 0.6927 - val_loss: 0.2460 - val_categorical_accuracy: 0.6835\n",
      "Epoch 13/20\n",
      "703/703 [==============================] - 11s 15ms/step - loss: 0.1935 - categorical_accuracy: 0.7013 - val_loss: 0.2414 - val_categorical_accuracy: 0.6709\n",
      "Epoch 14/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.1759 - categorical_accuracy: 0.6885 - val_loss: 0.2281 - val_categorical_accuracy: 0.6582\n",
      "Epoch 15/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.1611 - categorical_accuracy: 0.6842 - val_loss: 0.2225 - val_categorical_accuracy: 0.6582\n",
      "Epoch 16/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.1490 - categorical_accuracy: 0.6913 - val_loss: 0.2157 - val_categorical_accuracy: 0.7089\n",
      "Epoch 17/20\n",
      "703/703 [==============================] - 11s 15ms/step - loss: 0.1385 - categorical_accuracy: 0.6942 - val_loss: 0.2104 - val_categorical_accuracy: 0.6835\n",
      "Epoch 18/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.1280 - categorical_accuracy: 0.6771 - val_loss: 0.2064 - val_categorical_accuracy: 0.6962\n",
      "Epoch 19/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.1199 - categorical_accuracy: 0.6984 - val_loss: 0.2036 - val_categorical_accuracy: 0.6962\n",
      "Epoch 20/20\n",
      "703/703 [==============================] - 11s 16ms/step - loss: 0.1117 - categorical_accuracy: 0.6856 - val_loss: 0.2017 - val_categorical_accuracy: 0.6962\n"
     ]
    }
   ],
   "source": [
    "filter_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 20, input_length=180))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 915us/step\n",
      "loss: 0.20392031572302993\n",
      "categorical_accuracy: 0.6173469387755102\n"
     ]
    }
   ],
   "source": [
    "cnn_model = keras.models.load_model('model-conv1d.h5')\n",
    "metrics = cnn_model.evaluate(x_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "total_layers = len(cnn_model.layers)\n",
    "\n",
    "fl_index = total_layers-1\n",
    "\n",
    "feature_layer_model = Model(\n",
    "                     inputs=cnn_model.input,\n",
    "                     outputs=cnn_model.get_layer(index=fl_index).output)\n",
    "\n",
    "x_train_xg = feature_layer_model.predict(x_train)\n",
    "x_test_xg = feature_layer_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7545092226254437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Annisa Nurul Azhar\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = BinaryRelevance(XGBClassifier())\n",
    "clf.fit(x_train_xg, y_train)\n",
    "y_pred = clf.predict(x_test_xg)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7527145510221926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Annisa Nurul Azhar\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "clf = ClassifierChain(XGBClassifier())\n",
    "clf.fit(x_train_xg, y_train)\n",
    "y_pred = clf.predict(x_test_xg)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
